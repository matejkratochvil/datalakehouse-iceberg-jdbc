{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a5c8206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.9.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyiceberg import __version__\n",
    "\n",
    "__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9a9f41",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a890a18-6078-4574-8ade-7598ba91bf6b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowInvalid",
     "evalue": "Error creating dataset. Could not read schema from '/home/jovyan/notebooks/testdata/consuption/ConsumptionIndustry0.json'. Is this a 'json' file?: Could not open JSON input source '/home/jovyan/notebooks/testdata/consuption/ConsumptionIndustry0.json': Invalid: straddling object straddles two block boundaries (try to increase block size?)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mds\u001b[39;00m\n\u001b[1;32m      3\u001b[0m ds\u001b[38;5;241m.\u001b[39mJsonFileFormat()\n\u001b[0;32m----> 4\u001b[0m tbl_taxis \u001b[38;5;241m=\u001b[39m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/jovyan/notebooks/testdata/consuption/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjson\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m tbl_taxis\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pyarrow/dataset.py:794\u001b[0m, in \u001b[0;36mdataset\u001b[0;34m(source, schema, format, filesystem, partitioning, partition_base_dir, exclude_invalid_files, ignore_prefixes)\u001b[0m\n\u001b[1;32m    783\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    784\u001b[0m     schema\u001b[38;5;241m=\u001b[39mschema,\n\u001b[1;32m    785\u001b[0m     filesystem\u001b[38;5;241m=\u001b[39mfilesystem,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m     selector_ignore_prefixes\u001b[38;5;241m=\u001b[39mignore_prefixes\n\u001b[1;32m    791\u001b[0m )\n\u001b[1;32m    793\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_path_like(source):\n\u001b[0;32m--> 794\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_filesystem_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(source, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(_is_path_like(elem) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, FileInfo) \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m source):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pyarrow/dataset.py:486\u001b[0m, in \u001b[0;36m_filesystem_dataset\u001b[0;34m(source, schema, filesystem, partitioning, format, partition_base_dir, exclude_invalid_files, selector_ignore_prefixes)\u001b[0m\n\u001b[1;32m    478\u001b[0m options \u001b[38;5;241m=\u001b[39m FileSystemFactoryOptions(\n\u001b[1;32m    479\u001b[0m     partitioning\u001b[38;5;241m=\u001b[39mpartitioning,\n\u001b[1;32m    480\u001b[0m     partition_base_dir\u001b[38;5;241m=\u001b[39mpartition_base_dir,\n\u001b[1;32m    481\u001b[0m     exclude_invalid_files\u001b[38;5;241m=\u001b[39mexclude_invalid_files,\n\u001b[1;32m    482\u001b[0m     selector_ignore_prefixes\u001b[38;5;241m=\u001b[39mselector_ignore_prefixes\n\u001b[1;32m    483\u001b[0m )\n\u001b[1;32m    484\u001b[0m factory \u001b[38;5;241m=\u001b[39m FileSystemDatasetFactory(fs, paths_or_selector, \u001b[38;5;28mformat\u001b[39m, options)\n\u001b[0;32m--> 486\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfactory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pyarrow/_dataset.pyx:3138\u001b[0m, in \u001b[0;36mpyarrow._dataset.DatasetFactory.finish\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pyarrow/error.pxi:155\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pyarrow/error.pxi:92\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowInvalid\u001b[0m: Error creating dataset. Could not read schema from '/home/jovyan/notebooks/testdata/consuption/ConsumptionIndustry0.json'. Is this a 'json' file?: Could not open JSON input source '/home/jovyan/notebooks/testdata/consuption/ConsumptionIndustry0.json': Invalid: straddling object straddles two block boundaries (try to increase block size?)"
     ]
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pyarrow.dataset as ds\n",
    "ds.JsonFileFormat()\n",
    "tbl_taxis = ds.dataset('/home/jovyan/notebooks/testdata/consuption/',format='json')\n",
    "tbl_taxis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d2ac2a-7e21-4f5b-b357-a020797099fd",
   "metadata": {},
   "source": [
    "## Creating the table\n",
    "\n",
    "Next, create the namespace, and the `taxis` table from the schema that's derived from the Arrow schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fddb808",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiceberg.catalog import load_catalog\n",
    "from pyiceberg.exceptions import NamespaceAlreadyExistsError\n",
    "\n",
    "cat = load_catalog('default')\n",
    "\n",
    "try:\n",
    "    cat.create_namespace('default')\n",
    "except NamespaceAlreadyExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430bd828-f856-4230-aff7-94274fbce96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiceberg.exceptions import NoSuchTableError\n",
    "\n",
    "try:\n",
    "    cat.drop_table('default.taxis')\n",
    "except NoSuchTableError:\n",
    "    pass\n",
    "\n",
    "tbl = cat.create_table(\n",
    "    'default.taxis',\n",
    "    schema=tbl_taxis.schema\n",
    ")\n",
    "\n",
    "tbl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56818a92-12c6-4806-a700-3071b9b3753c",
   "metadata": {},
   "source": [
    "## Write the actual data into the table\n",
    "\n",
    "This will create a new snapshot on the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672a87b1-7132-489f-934c-8243016b20b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl.overwrite(tbl_taxis)\n",
    "\n",
    "tbl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87c4f8e-3d04-493b-9faf-292b39656a48",
   "metadata": {},
   "source": [
    "## Append more data\n",
    "\n",
    "Let's append another month of data to the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9b5f47-d696-4742-9b72-b4ea203bd8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl.append(pq.read_table('/home/iceberg/data/yellow_tripdata_2021-05.parquet'))\n",
    "tbl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa23071-8207-4c3d-86bc-db5bf4d768c0",
   "metadata": {},
   "source": [
    "## Load data into a PyArrow Dataframe\n",
    "\n",
    "We'll fetch the table using the REST catalog that comes with the setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794de3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = cat.load_table('default.taxis')\n",
    "\n",
    "sc = tbl.scan(row_filter=\"tpep_pickup_datetime >= '2021-05-01T00:00:00.000000'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ac7021",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sc.to_arrow().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e818e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7034fa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d7e6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb4b02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(column='fare_amount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f7cc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "stats.zscore(df['fare_amount'])\n",
    "\n",
    "# Remove everything larger than 3 stddev\n",
    "df = df[(np.abs(stats.zscore(df['fare_amount'])) < 3)]\n",
    "# Remove everything below zero\n",
    "df = df[df['fare_amount'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18771ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(column='fare_amount')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886c8408",
   "metadata": {},
   "source": [
    "# DuckDB\n",
    "\n",
    "Use DuckDB to Query the PyArrow Dataframe directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5d6fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "%config SqlMagic.autopandas = True\n",
    "%config SqlMagic.feedback = False\n",
    "%config SqlMagic.displaycon = False\n",
    "%sql duckdb:///:memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6f9522",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT * FROM df LIMIT 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5314f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql --save tip_amount --no-execute\n",
    "\n",
    "SELECT tip_amount\n",
    "FROM df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dec260",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sqlplot histogram --table df --column tip_amount --bins 22 --with tip_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989827d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql --save tip_amount_filtered --no-execute\n",
    "\n",
    "WITH tip_amount_stddev AS (\n",
    "    SELECT STDDEV_POP(tip_amount) AS tip_amount_stddev\n",
    "    FROM df\n",
    ")\n",
    "\n",
    "SELECT tip_amount\n",
    "FROM df, tip_amount_stddev\n",
    "WHERE tip_amount > 0\n",
    "  AND tip_amount < tip_amount_stddev * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1df179",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sqlplot histogram --table tip_amount_filtered --column tip_amount --bins 50 --with tip_amount_filtered\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
