services:
  minio:
    image: minio/minio:RELEASE.2025-04-22T22-12-26Z
    container_name: minio
    ports:
      - "9000:9000"  # API
      - "9001:9001"  # Console
    volumes:
      - ./s3data:/data
    environment:
      MINIO_ROOT_USER: admin
      MINIO_ROOT_PASSWORD: password
      MINIO_DEFAULT_BUCKETS: iceberg-warehouse
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    networks:
      - datalakehouse_network

  mcinit:
    image: minio/mc:RELEASE.2025-04-16T18-13-26Z
    container_name: mcinit
    depends_on:
      - minio
    restart: on-failure
    entrypoint: >
      /bin/sh -c "
      sleep 5;
      /usr/bin/mc alias set dockerminio http://minio:9000 admin password;
      /usr/bin/mc mb dockerminio/iceberg-warehouse;
      exit 0;
      "
    networks:
      - datalakehouse_network

  postgres:
    image: postgres:15
    container_name: postgres_catalog
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: iceberg
      POSTGRES_PASSWORD: icebergpassword
      POSTGRES_DB: iceberg_catalog
    volumes:
      - ./config/postgres/iceberg-setup.sql:/docker-entrypoint-initdb.d/iceberg-setup.sql
      - ./config/postgres/init.sql:/docker-entrypoint-initdb.d/init.sql
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U iceberg -d iceberg_catalog"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - datalakehouse_network

  trino-coordinator:
    image: trinodb/trino:475
    container_name: trino-coordinator
    ports:
      - "8080:8080"
    volumes:
      - ./config/trino/catalog:/etc/trino/catalog
    depends_on:
      minio:
        condition: service_healthy
      postgres:
        condition: service_healthy
    networks:
      - datalakehouse_network

# --- Spark Services ---
  spark-master:
    image: bitnami/spark:3.5.3 # Using a Bitnami Spark image for convenience, includes Hadoop client
    container_name: spark-master
    ports:
      - "8081:8080"  # Spark Master Web UI
      - "7077:7077"  # Spark Master RPC
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_SUBMIT_ARGS=--packages org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.9.0
    volumes:
      - ./config/spark/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
      # - ./notebooks:/opt/bitnami/spark/work-dir/notebooks # For Spark to access notebooks if needed (e.g. for spark-submit)
      - ./jars:/opt/bitnami/spark/jars/custom # For custom jars if needed
    depends_on:
      minio:
        condition: service_healthy
      postgres:
        condition: service_healthy
    networks:
      - datalakehouse_network

  spark-worker:
    image: bitnami/spark:3.5.3
    container_name: spark-worker-1
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077 # Connect to the Spark master
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_SUBMIT_ARGS=--packages org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.9.0

    volumes:
      - ./config/spark/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
      - ./jars:/opt/bitnami/spark/jars/custom
    depends_on:
      - spark-master
    networks:
      - datalakehouse_network

  jupyterlab:
    build:
      context: ./config/jupyterlab # Create a new directory for Jupyter Dockerfile
      dockerfile: Dockerfile
    container_name: jupyterlab
    # image: quay.io/jupyter/pyspark-notebook:spark-3.5.3
    # container_name: jupyterlab
    ports:
      - "8888:8888" # JupyterLab UI
      - "4040:4040" # Spark UI for PySpark driver
      - "4041:4041"
      - "4042:4042"
    volumes:
      - ./notebooks:/home/jovyan/notebooks
      - ./config:/home/jovyan/work/config
      - ./s3data:/home/jovyan/work/s3data
      - ./jars:/home/jovyan/jars # Mount jars to be accessible by PySpark in Jupyter
    environment:
      JUPYTER_ENABLE_LAB: "yes"
      JUPYTER_TOKEN: "icebergrocks"
      # Spark Configuration for PySpark in JupyterLab
      # These will be used when a SparkSession is created in the notebook
      PYSPARK_SUBMIT_ARGS: >-
        --master spark://spark-master:7077
        --conf spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions
        --conf spark.sql.catalog.spark_catalog=org.apache.iceberg.spark.SparkSessionCatalog
        --conf spark.sql.catalog.spark_catalog.type=hive
        --conf spark.sql.catalog.iceberg_jdbc.type=jdbc
        --conf spark.sql.catalog.iceberg_jdbc.uri=jdbc:postgresql://postgres_catalog:5432/iceberg_catalog
        --conf spark.sql.catalog.iceberg_jdbc.jdbc.user=iceberg
        --conf spark.sql.catalog.iceberg_jdbc.jdbc.password=icebergpassword
        --conf spark.sql.catalog.iceberg_jdbc.driver=org.postgresql.Driver
        --conf spark.sql.catalog.iceberg_jdbc.warehouse=s3a://iceberg-warehouse/
        --conf spark.hadoop.fs.s3a.endpoint=http://minio:9000
        --conf spark.hadoop.fs.s3a.access.key=admin
        --conf spark.hadoop.fs.s3a.secret.key=password
        --conf spark.hadoop.fs.s3a.path.style.access=true
        --conf spark.hadoop.fs.s3a.connection.ssl.enabled=false
        --conf spark.driver.extraJavaOptions="-Daws.region=eu-central-1 -Daws.overrideDefaultRegion=true"
        --conf spark.executor.extraJavaOptions="-Daws.region=eu-central-1 -Daws.overrideDefaultRegion=true"
        --packages org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.9.0,org.apache.hadoop:hadoop-aws:3.3.4,org.postgresql:postgresql:42.6.0
        pyspark-shell
    depends_on:
      - trino-coordinator
      - minio
      - postgres
      - spark-master
    networks:
      - datalakehouse_network

volumes:
  postgres_data:
networks:
  datalakehouse_network:
    name: datalakehouse_network